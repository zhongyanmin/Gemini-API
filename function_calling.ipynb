{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmyTBmc2UzDIX/xTGIFfcS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhongyanmin/Gemini-API/blob/main/function_calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi-lxR7TIqAi"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "pUJjcUcwOhyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schedule_meeting_function = {\n",
        "    \"name\": \"schedule_meeting\",\n",
        "    \"description\": \"Schedules a meeting with specified attendees at a given time and date.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"attendees\": {\n",
        "                \"type\": \"array\",\n",
        "                \"items\": {\"type\": \"string\"},\n",
        "                \"description\": \"List of people attending the meeting.\",\n",
        "            },\n",
        "            \"date\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Date of the meeting (e.g., '2024-07-29')\",\n",
        "            },\n",
        "            \"time\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Time of the meeting (e.g., '15:00')\",\n",
        "            },\n",
        "            \"topic\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The subject or topic of the meeting.\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"attendees\", \"date\", \"time\", \"topic\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Configure the client and tools\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "tools = types.Tool(function_declarations=[schedule_meeting_function])\n",
        "config = types.GenerateContentConfig(tools=[tools])\n",
        "\n",
        "# Send request with function declarations\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=\"Schedule a meeting with Bob and Alice for 03/14/2025 at 10:00 AM about the Q3 planning.\",\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "# Check for a function call\n",
        "if response.candidates[0].content.parts[0].function_call:\n",
        "    function_call = response.candidates[0].content.parts[0].function_call\n",
        "    print(f\"Function to call: {function_call.name}\")\n",
        "    print(f\"Arguments: {function_call.args}\")\n",
        "    #  In a real app, you would call your function here:\n",
        "    #  result = schedule_meeting(**function_call.args)\n",
        "else:\n",
        "    print(\"No function call found in the response.\")\n",
        "    print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGZM4QTtN5iR",
        "outputId": "37f278c4-8f40-44fa-a0a9-c52be2285276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function to call: schedule_meeting\n",
            "Arguments: {'topic': 'Q3 planning', 'attendees': ['Bob', 'Alice'], 'time': '10:00', 'date': '2025-03-14'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Define a function declaration\n",
        "\n",
        "Define a function and its declaration within your application code that allows users to set light values and make an API request. This function could call external services or APIs."
      ],
      "metadata": {
        "id": "EGnpvkzn4uk1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a3fc6c6"
      },
      "source": [
        "# Define a function that the model can call to control smart lights\n",
        "set_light_values_declaration = {\n",
        "    \"name\": \"set_light_values\",\n",
        "    \"description\": \"Sets the brightness and color temperature of a light.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"brightness\": {\n",
        "                \"type\": \"integer\",\n",
        "                \"description\": \"Light level from 0 to 100. Zero is off and 100 is full brightness\",\n",
        "            },\n",
        "            \"color_temp\": {\n",
        "                \"type\": \"string\",\n",
        "                \"enum\": [\"daylight\", \"cool\", \"warm\"],\n",
        "                \"description\": \"Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"brightness\", \"color_temp\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "# This is the actual function that would be called based on the model's suggestion\n",
        "def set_light_values(brightness: int, color_temp: str) -> dict[str, int | str]:\n",
        "    \"\"\"Set the brightness and color temperature of a room light. (mock API).\n",
        "\n",
        "    Args:\n",
        "        brightness: Light level from 0 to 100. Zero is off and 100 is full brightness\n",
        "        color_temp: Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the set brightness and color temperature.\n",
        "    \"\"\"\n",
        "    return {\"brightness\": brightness, \"colorTemperature\": color_temp}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Call the model with function declarations\n",
        "\n",
        "Once you have defined your function declarations, you can prompt the model to use them. It analyzes the prompt and function declarations and decides whether to respond directly or to call a function. If a function is called, the response object will contain a function call suggestion."
      ],
      "metadata": {
        "id": "6Z1SnOwP5Nu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = types.Tool(function_declarations=[set_light_values_declaration])\n",
        "config = types.GenerateContentConfig(tools=[tools])\n",
        "\n",
        "# Define user prompt\n",
        "contents = [\n",
        "    types.Content(\n",
        "        role=\"user\", parts=[types.Part(text=\"Turn the lights down to a romantic level\")]\n",
        "    )\n",
        "]\n",
        "\n",
        "# Send request with function declarations\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=contents,\n",
        "    config=config,\n",
        "\n",
        ")\n",
        "\n",
        "print(response.candidates[0].content.parts[0].function_call)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMYs2lbg3fQ0",
        "outputId": "3e61041d-7a9d-41cd-8b40-b9b2f686150c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id=None args={'color_temp': 'warm', 'brightness': 20} name='set_light_values'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "\n",
        "part = response.candidates[0].content.parts[0]\n",
        "if part.thought_signature:\n",
        "  print(base64.b64encode(part.thought_signature).decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZe0GBL7J9Mf",
        "outputId": "69eb1ef2-2399-452e-80b0-8f93ec9182b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CscCAVSoXO6fEYlblX05H/WuRx6BfU1ccbYkDjD2DQEBMhiW5noS6MS1280pKJJHruG1oB66+j/m8mnyFHVPgpNKJP09pGH2dUdoe2C2maDeBfLNDK/lEWfDlB56WWwJpOEVlIjI96lEpZpGmxrP5U8D44fT+LEvZMT0d2u7GWNBuAY2R1vHrEYHzv1SlH0vs+Y+0v9X+B4rwtZZmNsqnYwZ/mHycw+KLGrR7n6jcW4/uPo9KGCD2W9P5S7p6xqjlnuYv4uwgjie1O7mZ+93v84+Tqp/JzpWCXIG2hlQD4V0qiNUEAg8Pokzn9W02HW5bdXvBfND7D8QZq903hhJf/Nr0KvP/iSthrLR2n8U/i41lJHzoCv3g0esiYUOROQ/gob8TPk9JASk1rk694yEO2TjQxUZdc7ECPAmGMvYgukyteW7SkGGyAdH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Execute set_light_values function code\n",
        "\n",
        "Extract the function call details from the model's response, parse the arguments , and execute the set_light_values function."
      ],
      "metadata": {
        "id": "moqi5T156idg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract tool call details, it may not be in the first part.\n",
        "tool_call = response.candidates[0].content.parts[0].function_call\n",
        "\n",
        "if tool_call.name == \"set_light_values\":\n",
        "    result = set_light_values(**tool_call.args)\n",
        "    print(f\"Function execution result: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAdOImrU6pRH",
        "outputId": "e4fcf942-d7e8-4572-9e7a-a2a7ff5a604d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function execution result: {'brightness': 20, 'colorTemperature': 'warm'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.candidates[0].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RADemAHeIQdQ",
        "outputId": "0b3f9ae2-f397-4470-c20d-934a11d80c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parts=[Part(\n",
            "  function_call=FunctionCall(\n",
            "    args={\n",
            "      'brightness': 20,\n",
            "      'color_temp': 'warm'\n",
            "    },\n",
            "    name='set_light_values'\n",
            "  ),\n",
            "  thought_signature=b'\\n\\xc7\\x02\\x01T\\xa8\\\\\\xee\\x9f\\x11\\x89[\\x95}9\\x1f\\xf5\\xaeG\\x1e\\x81}M\\\\q\\xb6$\\x0e0\\xf6\\r\\x01\\x012\\x18\\x96\\xe6z\\x12\\xe8\\xc4\\xb5\\xdb\\xcd)(\\x92G\\xae\\xe1\\xb5\\xa0\\x1e\\xba\\xfa?\\xe6\\xf2i\\xf2\\x14uO\\x82\\x93J$\\xfd=\\xa4a\\xf6uGh{`\\xb6\\x99\\xa0\\xde\\x05\\xf2\\xcd\\x0c\\xaf\\xe5\\x11g\\xc3\\x94\\x1ezYl\\t\\xa4...'\n",
            ")] role='model'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Create user friendly response with function result and call the model again\n",
        "\n",
        "Finally, send the result of the function execution back to the model so it can incorporate this information into its final response to the user."
      ],
      "metadata": {
        "id": "xoIDQmxi5U4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function response part\n",
        "function_response_part = types.Part.from_function_response(\n",
        "    name=tool_call.name,\n",
        "    response={\"result\": result},\n",
        ")\n",
        "\n",
        "# Append function call and result of the function execution to contents\n",
        "contents.append(response.candidates[0].content) # Append the content from the model's response.\n",
        "contents.append(types.Content(role=\"user\", parts=[function_response_part])) # Append the function response\n",
        "\n",
        "final_response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    config=config,\n",
        "    contents=contents,\n",
        ")\n",
        "\n",
        "print(final_response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqQTcGiE5ZgW",
        "outputId": "1622369a-4354-4f7e-c253-3fff631e259b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lights are now set to a romantic level.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "power_disco_ball = {\n",
        "    \"name\": \"power_disco_ball\",\n",
        "    \"description\": \"Powers the spinning disco ball.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"power\": {\n",
        "                \"type\": \"boolean\",\n",
        "                \"description\": \"Whether to turn the disco ball on or off.\",\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"power\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "start_music = {\n",
        "    \"name\": \"start_music\",\n",
        "    \"description\": \"Play some music matching the specified parameters.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"energetic\": {\n",
        "                \"type\": \"boolean\",\n",
        "                \"description\": \"Whether the music is energetic or not.\",\n",
        "            },\n",
        "            \"loud\": {\n",
        "                \"type\": \"boolean\",\n",
        "                \"description\": \"Whether the music is loud or not.\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"energetic\", \"loud\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "dim_lights = {\n",
        "    \"name\": \"dim_lights\",\n",
        "    \"description\": \"Dim the lights.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"brightness\": {\n",
        "                \"type\": \"number\",\n",
        "                \"description\": \"The brightness of the lights, 0.0 is off, 1.0 is full.\",\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"brightness\"],\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "SoBrwiJzLG-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Configure the client and tools\n",
        "# client = genai.Client()\n",
        "house_tools = [\n",
        "    types.Tool(function_declarations=[power_disco_ball, start_music, dim_lights])\n",
        "]\n",
        "config = types.GenerateContentConfig(\n",
        "    tools=house_tools,\n",
        "    automatic_function_calling=types.AutomaticFunctionCallingConfig(\n",
        "        disable=True\n",
        "    ),\n",
        "    # Force the model to call 'any' function, instead of chatting.\n",
        "    tool_config=types.ToolConfig(\n",
        "        function_calling_config=types.FunctionCallingConfig(mode='ANY')\n",
        "    ),\n",
        ")\n",
        "\n",
        "chat = client.chats.create(model=\"gemini-2.5-flash\", config=config)\n",
        "response = chat.send_message(\"Turn this place into a party!\")\n",
        "\n",
        "# Print out each of the function calls requested from this single call\n",
        "print(\"Example 1: Forced function calling\")\n",
        "for fn in response.function_calls:\n",
        "    args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
        "    print(f\"{fn.name}({args})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMAvBkHDLKWb",
        "outputId": "3ea88a49-ecdb-4890-93ce-4d06d58826e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1: Forced function calling\n",
            "start_music(loud=True, energetic=True)\n",
            "power_disco_ball(power=True)\n",
            "dim_lights(brightness=0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual function implementations\n",
        "def power_disco_ball_impl(power: bool) -> dict:\n",
        "    \"\"\"Powers the spinning disco ball.\n",
        "\n",
        "    Args:\n",
        "        power: Whether to turn the disco ball on or off.\n",
        "\n",
        "    Returns:\n",
        "        A status dictionary indicating the current state.\n",
        "    \"\"\"\n",
        "    return {\"status\": f\"Disco ball powered {'on' if power else 'off'}\"}\n",
        "\n",
        "def start_music_impl(energetic: bool, loud: bool) -> dict:\n",
        "    \"\"\"Play some music matching the specified parameters.\n",
        "\n",
        "    Args:\n",
        "        energetic: Whether the music is energetic or not.\n",
        "        loud: Whether the music is loud or not.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the music settings.\n",
        "    \"\"\"\n",
        "    music_type = \"energetic\" if energetic else \"chill\"\n",
        "    volume = \"loud\" if loud else \"quiet\"\n",
        "    return {\"music_type\": music_type, \"volume\": volume}\n",
        "\n",
        "def dim_lights_impl(brightness: float) -> dict:\n",
        "    \"\"\"Dim the lights.\n",
        "\n",
        "    Args:\n",
        "        brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the new brightness setting.\n",
        "    \"\"\"\n",
        "    return {\"brightness\": brightness}\n",
        "\n",
        "# Configure the client\n",
        "# client = genai.Client()\n",
        "config = types.GenerateContentConfig(\n",
        "    tools=[power_disco_ball_impl, start_music_impl, dim_lights_impl]\n",
        ")\n",
        "\n",
        "# Make the request\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=\"Do everything you need to this place into party!\",\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "print(\"\\nExample 2: Automatic function calling\")\n",
        "print(response.text)\n",
        "# I've turned on the disco ball, started playing loud and energetic music, and dimmed the lights to 50% brightness. Let's get this party started!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9xwtN9DMF3m",
        "outputId": "e21fdfa1-c3bd-4846-c894-1ecd122973b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example 2: Automatic function calling\n",
            "Alright, the disco ball is on, the music is pumping loud and energetic, and the lights are dimmed to a perfect party ambiance! Let's get this party started!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™\n",
        "# Google Colabã®ç’°å¢ƒã§ã¯ã€é€šå¸¸ã™ã§ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã™ãŒã€\n",
        "# æœ€æ–°ç‰ˆã«æ›´æ–°ã™ã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã®è¡Œã‚’æœ‰åŠ¹ã«ã—ã¾ã™ã€‚\n",
        "!pip install -q -U google-generativeai\n",
        "\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# ã‚¹ãƒ†ãƒƒãƒ—1: APIã‚­ãƒ¼ã®è¨­å®š\n",
        "# ----------------------------------------------------\n",
        "# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚ã€Colabã®ã€Œã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã€æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚\n",
        "# å·¦å´ã®ãƒ‘ãƒãƒ«ã«ã‚ã‚‹ã€Œéµã€ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€ã€Œæ–°ã—ã„ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’è¿½åŠ ã€ã§\n",
        "# åå‰: GOOGLE_API_KEY\n",
        "# å€¤: ã‚ãªãŸã®Gemini APIã‚­ãƒ¼\n",
        "# ã¨è¨­å®šã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "# ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "except ImportError:\n",
        "    print(\"Colabã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆæ©Ÿèƒ½ãŒä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã‚’ç›´æ¥è¨­å®šã—ã¾ã™ã€‚\")\n",
        "    # ä»£ã‚ã‚Šã«ã€APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã¨ã—ã¦è¨­å®šã™ã‚‹ã‹ã€ã“ã“ã«ç›´æ¥å…¥åŠ›ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™\n",
        "    # genai.configure(api_key=\"YOUR_API_KEY\")\n",
        "    # æœ¬ç•ªç’°å¢ƒã§ã¯ã“ã®æ–¹æ³•ã¯é¿ã‘ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ„ãƒ¼ãƒ«ï¼ˆé–¢æ•°ï¼‰ã®å®šç¾©\n",
        "# ----------------------------------------------------\n",
        "# ãƒ©ã‚¤ãƒˆã‚’ã‚ªãƒ³ã«ã™ã‚‹é–¢æ•°\n",
        "def turn_on_the_lights():\n",
        "    \"\"\"å®¶ã®ãƒ©ã‚¤ãƒˆã‚’ã‚ªãƒ³ã«ã—ã¾ã™ã€‚\"\"\"\n",
        "    print(\"ğŸ’¡ ãƒ©ã‚¤ãƒˆã‚’ã‚ªãƒ³ã«ã—ã¾ã—ãŸã€‚\")\n",
        "    return {\"status\": \"success\", \"message\": \"ãƒ©ã‚¤ãƒˆã‚’ã‚ªãƒ³ã«ã—ã¾ã—ãŸ\"}\n",
        "\n",
        "# ãƒ©ã‚¤ãƒˆã‚’ã‚ªãƒ•ã«ã™ã‚‹é–¢æ•°\n",
        "def turn_off_the_lights():\n",
        "    \"\"\"å®¶ã®ãƒ©ã‚¤ãƒˆã‚’ã‚ªãƒ•ã«ã—ã¾ã™ã€‚\"\"\"\n",
        "    print(\"ğŸ’¡ ãƒ©ã‚¤ãƒˆã‚’ã‚ªãƒ•ã«ã—ã¾ã—ãŸã€‚\")\n",
        "    return {\"status\": \"success\", \"message\": \"ãƒ©ã‚¤ãƒˆã‚’ã‚ªãƒ•ã«ã—ã¾ã—ãŸ\"}\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ„ãƒ¼ãƒ«ï¼ˆé–¢æ•°ã®ã‚¹ã‚­ãƒ¼ãƒï¼‰ã‚’Geminiã«å®£è¨€\n",
        "# ----------------------------------------------------\n",
        "# `genai.Tool.from_function`ã‚’ä½¿ã£ã¦ã€Pythoné–¢æ•°ã‹ã‚‰ç›´æ¥ãƒ„ãƒ¼ãƒ«ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
        "# turn_on_the_lights_tool = genai.Tool.from_function(turn_on_the_lights)\n",
        "# turn_off_the_lights_tool = genai.Tool.from_function(turn_off_the_lights)\n",
        "\n",
        "# ãƒ„ãƒ¼ãƒ«ãƒªã‚¹ãƒˆ\n",
        "# tools = [turn_on_the_lights_tool, turn_off_the_lights_tool]\n",
        "tools = [turn_on_the_lights, turn_off_the_lights]\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# ã‚¹ãƒ†ãƒƒãƒ—4: Geminiãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã¨å¯¾è©±ã®å®Ÿè¡Œ\n",
        "# ----------------------------------------------------\n",
        "# 'gemini-2.5-flash'ãƒ¢ãƒ‡ãƒ«ã‚’ã€å®šç¾©ã—ãŸãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦åˆæœŸåŒ–ã—ã¾ã™ã€‚\n",
        "model = genai.GenerativeModel('gemini-2.5-flash', tools=tools)\n",
        "\n",
        "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å®šç¾©\n",
        "prompt = \"ãƒ©ã‚¤ãƒˆã‚’ã‚ªãƒ³ã«ã—ã¦ã€10ç§’å¾…ã£ã¦ã‹ã‚‰ã‚ªãƒ•ã«ã—ã¦ã€‚\"\n",
        "\n",
        "# Initialize contents with the initial prompt\n",
        "contents = [{\"role\": \"user\", \"parts\": [{\"text\": prompt}]}]\n",
        "\n",
        "# å¯¾è©±ã‚’é–‹å§‹\n",
        "print(\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:\", prompt)\n",
        "print(\"GeminiãŒå¿œç­”ã‚’ç”Ÿæˆä¸­...\")\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ä¿¡\n",
        "response = model.generate_content(contents=contents)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ¢ãƒ‡ãƒ«ã®å¿œç­”ã‚’å‡¦ç†\n",
        "# ----------------------------------------------------\n",
        "# ãƒ¢ãƒ‡ãƒ«ã®å¿œç­”ãŒãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®å ´åˆ\n",
        "if response.candidates[0].content.parts[0].function_call:\n",
        "    function_call = response.candidates[0].content.parts[0].function_call\n",
        "\n",
        "    # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®å†…å®¹ã‚’è¡¨ç¤º\n",
        "    print(\"\\nGeminiã‹ã‚‰ã®å¿œç­”ï¼ˆãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ï¼‰:\")\n",
        "    print(json.dumps(function_call.to_dict(), indent=2))\n",
        "\n",
        "    function_name = function_call.name\n",
        "\n",
        "    if function_name == \"turn_on_the_lights\":\n",
        "        # turn_on_the_lightsé–¢æ•°ã‚’å®Ÿè¡Œ\n",
        "        result = turn_on_the_lights()\n",
        "\n",
        "        # 10ç§’å¾…ã¤\n",
        "        print(\"â³ 10ç§’é–“å¾…æ©Ÿã—ã¾ã™...\")\n",
        "        time.sleep(10)\n",
        "\n",
        "        # Next conversation turn: feed the result back to Gemini\n",
        "        # This part prompts Gemini to call \"turn_off_the_lights\"\n",
        "        print(\"ğŸ’¡ 10 seconds have passed. Prompting for the next action.\")\n",
        "\n",
        "        # Append the model's response and the function response to the conversation history\n",
        "        contents.append(response.candidates[0].content)\n",
        "        contents.append({\"role\": \"function\", \"parts\": [{\"functionResponse\": {\"name\": \"turn_on_the_lights\", \"response\": result}}]})\n",
        "\n",
        "        second_response = model.generate_content(\n",
        "            contents=contents, # Pass the updated conversation history\n",
        "            tools=[genai.Tool.from_function(turn_off_the_lights)] # Pass the tool as a list\n",
        "        )\n",
        "\n",
        "        # Here, a second tool call (to turn off) will occur\n",
        "        second_function_call = second_response.candidates[0].content.parts[0].function_call\n",
        "        if second_function_call.name == \"turn_off_the_lights\":\n",
        "            # Execute the turn_off_the_lights function\n",
        "            result_off = turn_off_the_lights()\n",
        "\n",
        "            # Generate the final response from Gemini\n",
        "            contents.append(second_response.candidates[0].content)\n",
        "            contents.append({\"role\": \"function\", \"parts\": [{\"functionResponse\": {\"name\": \"turn_off_the_lights\", \"response\": result_off}}]})\n",
        "\n",
        "            final_response = model.generate_content(\n",
        "                contents=contents\n",
        "            )\n",
        "            print(\"\\nGeminiã‹ã‚‰ã®æœ€çµ‚çš„ãªå¿œç­”:\")\n",
        "            display(Markdown(final_response.text))\n",
        "\n",
        "    else:\n",
        "        print(f\"ä¸æ˜ãªãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—: {function_name}\")\n",
        "else:\n",
        "    # If the response is text\n",
        "    print(\"\\nGeminiã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”:\")\n",
        "    display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "tiV9PJiyNq-B",
        "outputId": "5515a2f7-8687-48da-e6c4-d69f6ab2bc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: ãƒ©ã‚¤ãƒˆã‚’ã‚ªãƒ³ã«ã—ã¦ã€10ç§’å¾…ã£ã¦ã‹ã‚‰ã‚ªãƒ•ã«ã—ã¦ã€‚\n",
            "GeminiãŒå¿œç­”ã‚’ç”Ÿæˆä¸­...\n",
            "\n",
            "Geminiã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "10ç§’å¾…ã¤ã€ã¨ã„ã†å‹•ä½œã¯ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚ãƒ©ã‚¤ãƒˆã‚’ã‚ªãƒ³ãƒ»ã‚ªãƒ•ã™ã‚‹ã“ã¨ã®ã¿å®Ÿè¡Œã§ãã¾ã™ãŒã€ã„ã‹ãŒã„ãŸã—ã¾ã™ã‹ï¼Ÿ"
          },
          "metadata": {}
        }
      ]
    }
  ]
}