{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmyTBmc2UzDIX/xTGIFfcS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhongyanmin/Gemini-API/blob/main/function_calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi-lxR7TIqAi"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "pUJjcUcwOhyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schedule_meeting_function = {\n",
        "    \"name\": \"schedule_meeting\",\n",
        "    \"description\": \"Schedules a meeting with specified attendees at a given time and date.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"attendees\": {\n",
        "                \"type\": \"array\",\n",
        "                \"items\": {\"type\": \"string\"},\n",
        "                \"description\": \"List of people attending the meeting.\",\n",
        "            },\n",
        "            \"date\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Date of the meeting (e.g., '2024-07-29')\",\n",
        "            },\n",
        "            \"time\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Time of the meeting (e.g., '15:00')\",\n",
        "            },\n",
        "            \"topic\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The subject or topic of the meeting.\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"attendees\", \"date\", \"time\", \"topic\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Configure the client and tools\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "tools = types.Tool(function_declarations=[schedule_meeting_function])\n",
        "config = types.GenerateContentConfig(tools=[tools])\n",
        "\n",
        "# Send request with function declarations\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=\"Schedule a meeting with Bob and Alice for 03/14/2025 at 10:00 AM about the Q3 planning.\",\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "# Check for a function call\n",
        "if response.candidates[0].content.parts[0].function_call:\n",
        "    function_call = response.candidates[0].content.parts[0].function_call\n",
        "    print(f\"Function to call: {function_call.name}\")\n",
        "    print(f\"Arguments: {function_call.args}\")\n",
        "    #  In a real app, you would call your function here:\n",
        "    #  result = schedule_meeting(**function_call.args)\n",
        "else:\n",
        "    print(\"No function call found in the response.\")\n",
        "    print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGZM4QTtN5iR",
        "outputId": "37f278c4-8f40-44fa-a0a9-c52be2285276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function to call: schedule_meeting\n",
            "Arguments: {'topic': 'Q3 planning', 'attendees': ['Bob', 'Alice'], 'time': '10:00', 'date': '2025-03-14'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Define a function declaration\n",
        "\n",
        "Define a function and its declaration within your application code that allows users to set light values and make an API request. This function could call external services or APIs."
      ],
      "metadata": {
        "id": "EGnpvkzn4uk1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a3fc6c6"
      },
      "source": [
        "# Define a function that the model can call to control smart lights\n",
        "set_light_values_declaration = {\n",
        "    \"name\": \"set_light_values\",\n",
        "    \"description\": \"Sets the brightness and color temperature of a light.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"brightness\": {\n",
        "                \"type\": \"integer\",\n",
        "                \"description\": \"Light level from 0 to 100. Zero is off and 100 is full brightness\",\n",
        "            },\n",
        "            \"color_temp\": {\n",
        "                \"type\": \"string\",\n",
        "                \"enum\": [\"daylight\", \"cool\", \"warm\"],\n",
        "                \"description\": \"Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"brightness\", \"color_temp\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "# This is the actual function that would be called based on the model's suggestion\n",
        "def set_light_values(brightness: int, color_temp: str) -> dict[str, int | str]:\n",
        "    \"\"\"Set the brightness and color temperature of a room light. (mock API).\n",
        "\n",
        "    Args:\n",
        "        brightness: Light level from 0 to 100. Zero is off and 100 is full brightness\n",
        "        color_temp: Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the set brightness and color temperature.\n",
        "    \"\"\"\n",
        "    return {\"brightness\": brightness, \"colorTemperature\": color_temp}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Call the model with function declarations\n",
        "\n",
        "Once you have defined your function declarations, you can prompt the model to use them. It analyzes the prompt and function declarations and decides whether to respond directly or to call a function. If a function is called, the response object will contain a function call suggestion."
      ],
      "metadata": {
        "id": "6Z1SnOwP5Nu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = types.Tool(function_declarations=[set_light_values_declaration])\n",
        "config = types.GenerateContentConfig(tools=[tools])\n",
        "\n",
        "# Define user prompt\n",
        "contents = [\n",
        "    types.Content(\n",
        "        role=\"user\", parts=[types.Part(text=\"Turn the lights down to a romantic level\")]\n",
        "    )\n",
        "]\n",
        "\n",
        "# Send request with function declarations\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=contents,\n",
        "    config=config,\n",
        "\n",
        ")\n",
        "\n",
        "print(response.candidates[0].content.parts[0].function_call)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMYs2lbg3fQ0",
        "outputId": "3e61041d-7a9d-41cd-8b40-b9b2f686150c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id=None args={'color_temp': 'warm', 'brightness': 20} name='set_light_values'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "\n",
        "part = response.candidates[0].content.parts[0]\n",
        "if part.thought_signature:\n",
        "  print(base64.b64encode(part.thought_signature).decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZe0GBL7J9Mf",
        "outputId": "69eb1ef2-2399-452e-80b0-8f93ec9182b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CscCAVSoXO6fEYlblX05H/WuRx6BfU1ccbYkDjD2DQEBMhiW5noS6MS1280pKJJHruG1oB66+j/m8mnyFHVPgpNKJP09pGH2dUdoe2C2maDeBfLNDK/lEWfDlB56WWwJpOEVlIjI96lEpZpGmxrP5U8D44fT+LEvZMT0d2u7GWNBuAY2R1vHrEYHzv1SlH0vs+Y+0v9X+B4rwtZZmNsqnYwZ/mHycw+KLGrR7n6jcW4/uPo9KGCD2W9P5S7p6xqjlnuYv4uwgjie1O7mZ+93v84+Tqp/JzpWCXIG2hlQD4V0qiNUEAg8Pokzn9W02HW5bdXvBfND7D8QZq903hhJf/Nr0KvP/iSthrLR2n8U/i41lJHzoCv3g0esiYUOROQ/gob8TPk9JASk1rk694yEO2TjQxUZdc7ECPAmGMvYgukyteW7SkGGyAdH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Execute set_light_values function code\n",
        "\n",
        "Extract the function call details from the model's response, parse the arguments , and execute the set_light_values function."
      ],
      "metadata": {
        "id": "moqi5T156idg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract tool call details, it may not be in the first part.\n",
        "tool_call = response.candidates[0].content.parts[0].function_call\n",
        "\n",
        "if tool_call.name == \"set_light_values\":\n",
        "    result = set_light_values(**tool_call.args)\n",
        "    print(f\"Function execution result: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAdOImrU6pRH",
        "outputId": "e4fcf942-d7e8-4572-9e7a-a2a7ff5a604d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function execution result: {'brightness': 20, 'colorTemperature': 'warm'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.candidates[0].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RADemAHeIQdQ",
        "outputId": "0b3f9ae2-f397-4470-c20d-934a11d80c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parts=[Part(\n",
            "  function_call=FunctionCall(\n",
            "    args={\n",
            "      'brightness': 20,\n",
            "      'color_temp': 'warm'\n",
            "    },\n",
            "    name='set_light_values'\n",
            "  ),\n",
            "  thought_signature=b'\\n\\xc7\\x02\\x01T\\xa8\\\\\\xee\\x9f\\x11\\x89[\\x95}9\\x1f\\xf5\\xaeG\\x1e\\x81}M\\\\q\\xb6$\\x0e0\\xf6\\r\\x01\\x012\\x18\\x96\\xe6z\\x12\\xe8\\xc4\\xb5\\xdb\\xcd)(\\x92G\\xae\\xe1\\xb5\\xa0\\x1e\\xba\\xfa?\\xe6\\xf2i\\xf2\\x14uO\\x82\\x93J$\\xfd=\\xa4a\\xf6uGh{`\\xb6\\x99\\xa0\\xde\\x05\\xf2\\xcd\\x0c\\xaf\\xe5\\x11g\\xc3\\x94\\x1ezYl\\t\\xa4...'\n",
            ")] role='model'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Create user friendly response with function result and call the model again\n",
        "\n",
        "Finally, send the result of the function execution back to the model so it can incorporate this information into its final response to the user."
      ],
      "metadata": {
        "id": "xoIDQmxi5U4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function response part\n",
        "function_response_part = types.Part.from_function_response(\n",
        "    name=tool_call.name,\n",
        "    response={\"result\": result},\n",
        ")\n",
        "\n",
        "# Append function call and result of the function execution to contents\n",
        "contents.append(response.candidates[0].content) # Append the content from the model's response.\n",
        "contents.append(types.Content(role=\"user\", parts=[function_response_part])) # Append the function response\n",
        "\n",
        "final_response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    config=config,\n",
        "    contents=contents,\n",
        ")\n",
        "\n",
        "print(final_response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqQTcGiE5ZgW",
        "outputId": "1622369a-4354-4f7e-c253-3fff631e259b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lights are now set to a romantic level.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "power_disco_ball = {\n",
        "    \"name\": \"power_disco_ball\",\n",
        "    \"description\": \"Powers the spinning disco ball.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"power\": {\n",
        "                \"type\": \"boolean\",\n",
        "                \"description\": \"Whether to turn the disco ball on or off.\",\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"power\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "start_music = {\n",
        "    \"name\": \"start_music\",\n",
        "    \"description\": \"Play some music matching the specified parameters.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"energetic\": {\n",
        "                \"type\": \"boolean\",\n",
        "                \"description\": \"Whether the music is energetic or not.\",\n",
        "            },\n",
        "            \"loud\": {\n",
        "                \"type\": \"boolean\",\n",
        "                \"description\": \"Whether the music is loud or not.\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"energetic\", \"loud\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "dim_lights = {\n",
        "    \"name\": \"dim_lights\",\n",
        "    \"description\": \"Dim the lights.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"brightness\": {\n",
        "                \"type\": \"number\",\n",
        "                \"description\": \"The brightness of the lights, 0.0 is off, 1.0 is full.\",\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"brightness\"],\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "SoBrwiJzLG-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Configure the client and tools\n",
        "# client = genai.Client()\n",
        "house_tools = [\n",
        "    types.Tool(function_declarations=[power_disco_ball, start_music, dim_lights])\n",
        "]\n",
        "config = types.GenerateContentConfig(\n",
        "    tools=house_tools,\n",
        "    automatic_function_calling=types.AutomaticFunctionCallingConfig(\n",
        "        disable=True\n",
        "    ),\n",
        "    # Force the model to call 'any' function, instead of chatting.\n",
        "    tool_config=types.ToolConfig(\n",
        "        function_calling_config=types.FunctionCallingConfig(mode='ANY')\n",
        "    ),\n",
        ")\n",
        "\n",
        "chat = client.chats.create(model=\"gemini-2.5-flash\", config=config)\n",
        "response = chat.send_message(\"Turn this place into a party!\")\n",
        "\n",
        "# Print out each of the function calls requested from this single call\n",
        "print(\"Example 1: Forced function calling\")\n",
        "for fn in response.function_calls:\n",
        "    args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
        "    print(f\"{fn.name}({args})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMAvBkHDLKWb",
        "outputId": "3ea88a49-ecdb-4890-93ce-4d06d58826e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1: Forced function calling\n",
            "start_music(loud=True, energetic=True)\n",
            "power_disco_ball(power=True)\n",
            "dim_lights(brightness=0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual function implementations\n",
        "def power_disco_ball_impl(power: bool) -> dict:\n",
        "    \"\"\"Powers the spinning disco ball.\n",
        "\n",
        "    Args:\n",
        "        power: Whether to turn the disco ball on or off.\n",
        "\n",
        "    Returns:\n",
        "        A status dictionary indicating the current state.\n",
        "    \"\"\"\n",
        "    return {\"status\": f\"Disco ball powered {'on' if power else 'off'}\"}\n",
        "\n",
        "def start_music_impl(energetic: bool, loud: bool) -> dict:\n",
        "    \"\"\"Play some music matching the specified parameters.\n",
        "\n",
        "    Args:\n",
        "        energetic: Whether the music is energetic or not.\n",
        "        loud: Whether the music is loud or not.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the music settings.\n",
        "    \"\"\"\n",
        "    music_type = \"energetic\" if energetic else \"chill\"\n",
        "    volume = \"loud\" if loud else \"quiet\"\n",
        "    return {\"music_type\": music_type, \"volume\": volume}\n",
        "\n",
        "def dim_lights_impl(brightness: float) -> dict:\n",
        "    \"\"\"Dim the lights.\n",
        "\n",
        "    Args:\n",
        "        brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the new brightness setting.\n",
        "    \"\"\"\n",
        "    return {\"brightness\": brightness}\n",
        "\n",
        "# Configure the client\n",
        "# client = genai.Client()\n",
        "config = types.GenerateContentConfig(\n",
        "    tools=[power_disco_ball_impl, start_music_impl, dim_lights_impl]\n",
        ")\n",
        "\n",
        "# Make the request\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=\"Do everything you need to this place into party!\",\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "print(\"\\nExample 2: Automatic function calling\")\n",
        "print(response.text)\n",
        "# I've turned on the disco ball, started playing loud and energetic music, and dimmed the lights to 50% brightness. Let's get this party started!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9xwtN9DMF3m",
        "outputId": "e21fdfa1-c3bd-4846-c894-1ecd122973b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example 2: Automatic function calling\n",
            "Alright, the disco ball is on, the music is pumping loud and energetic, and the lights are dimmed to a perfect party ambiance! Let's get this party started!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリをインストールします\n",
        "# Google Colabの環境では、通常すでにインストールされていますが、\n",
        "# 最新版に更新するために、以下の行を有効にします。\n",
        "!pip install -q -U google-generativeai\n",
        "\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# ステップ1: APIキーの設定\n",
        "# ----------------------------------------------------\n",
        "# セキュリティのため、Colabの「シークレット」機能を使用することを強く推奨します。\n",
        "# 左側のパネルにある「鍵」アイコンをクリックし、「新しいシークレットを追加」で\n",
        "# 名前: GOOGLE_API_KEY\n",
        "# 値: あなたのGemini APIキー\n",
        "# と設定してください。\n",
        "\n",
        "# シークレットからAPIキーを取得\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "except ImportError:\n",
        "    print(\"Colabのシークレット機能が使用できません。APIキーを直接設定します。\")\n",
        "    # 代わりに、APIキーを環境変数として設定するか、ここに直接入力することも可能です\n",
        "    # genai.configure(api_key=\"YOUR_API_KEY\")\n",
        "    # 本番環境ではこの方法は避けてください。\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# ステップ2: ツール（関数）の定義\n",
        "# ----------------------------------------------------\n",
        "# ライトをオンにする関数\n",
        "def turn_on_the_lights():\n",
        "    \"\"\"家のライトをオンにします。\"\"\"\n",
        "    print(\"💡 ライトをオンにしました。\")\n",
        "    return {\"status\": \"success\", \"message\": \"ライトをオンにしました\"}\n",
        "\n",
        "# ライトをオフにする関数\n",
        "def turn_off_the_lights():\n",
        "    \"\"\"家のライトをオフにします。\"\"\"\n",
        "    print(\"💡 ライトをオフにしました。\")\n",
        "    return {\"status\": \"success\", \"message\": \"ライトをオフにしました\"}\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# ステップ3: ツール（関数のスキーマ）をGeminiに宣言\n",
        "# ----------------------------------------------------\n",
        "# `genai.Tool.from_function`を使って、Python関数から直接ツールを定義します。\n",
        "# turn_on_the_lights_tool = genai.Tool.from_function(turn_on_the_lights)\n",
        "# turn_off_the_lights_tool = genai.Tool.from_function(turn_off_the_lights)\n",
        "\n",
        "# ツールリスト\n",
        "# tools = [turn_on_the_lights_tool, turn_off_the_lights_tool]\n",
        "tools = [turn_on_the_lights, turn_off_the_lights]\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# ステップ4: Geminiモデルの初期化と対話の実行\n",
        "# ----------------------------------------------------\n",
        "# 'gemini-2.5-flash'モデルを、定義したツールを使って初期化します。\n",
        "model = genai.GenerativeModel('gemini-2.5-flash', tools=tools)\n",
        "\n",
        "# プロンプトの定義\n",
        "prompt = \"ライトをオンにして、10秒待ってからオフにして。\"\n",
        "\n",
        "# Initialize contents with the initial prompt\n",
        "contents = [{\"role\": \"user\", \"parts\": [{\"text\": prompt}]}]\n",
        "\n",
        "# 対話を開始\n",
        "print(\"ユーザーのプロンプト:\", prompt)\n",
        "print(\"Geminiが応答を生成中...\")\n",
        "\n",
        "# モデルにプロンプトを送信\n",
        "response = model.generate_content(contents=contents)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# ステップ5: モデルの応答を処理\n",
        "# ----------------------------------------------------\n",
        "# モデルの応答がツール呼び出しの場合\n",
        "if response.candidates[0].content.parts[0].function_call:\n",
        "    function_call = response.candidates[0].content.parts[0].function_call\n",
        "\n",
        "    # ツール呼び出しの内容を表示\n",
        "    print(\"\\nGeminiからの応答（ツール呼び出し）:\")\n",
        "    print(json.dumps(function_call.to_dict(), indent=2))\n",
        "\n",
        "    function_name = function_call.name\n",
        "\n",
        "    if function_name == \"turn_on_the_lights\":\n",
        "        # turn_on_the_lights関数を実行\n",
        "        result = turn_on_the_lights()\n",
        "\n",
        "        # 10秒待つ\n",
        "        print(\"⏳ 10秒間待機します...\")\n",
        "        time.sleep(10)\n",
        "\n",
        "        # Next conversation turn: feed the result back to Gemini\n",
        "        # This part prompts Gemini to call \"turn_off_the_lights\"\n",
        "        print(\"💡 10 seconds have passed. Prompting for the next action.\")\n",
        "\n",
        "        # Append the model's response and the function response to the conversation history\n",
        "        contents.append(response.candidates[0].content)\n",
        "        contents.append({\"role\": \"function\", \"parts\": [{\"functionResponse\": {\"name\": \"turn_on_the_lights\", \"response\": result}}]})\n",
        "\n",
        "        second_response = model.generate_content(\n",
        "            contents=contents, # Pass the updated conversation history\n",
        "            tools=[genai.Tool.from_function(turn_off_the_lights)] # Pass the tool as a list\n",
        "        )\n",
        "\n",
        "        # Here, a second tool call (to turn off) will occur\n",
        "        second_function_call = second_response.candidates[0].content.parts[0].function_call\n",
        "        if second_function_call.name == \"turn_off_the_lights\":\n",
        "            # Execute the turn_off_the_lights function\n",
        "            result_off = turn_off_the_lights()\n",
        "\n",
        "            # Generate the final response from Gemini\n",
        "            contents.append(second_response.candidates[0].content)\n",
        "            contents.append({\"role\": \"function\", \"parts\": [{\"functionResponse\": {\"name\": \"turn_off_the_lights\", \"response\": result_off}}]})\n",
        "\n",
        "            final_response = model.generate_content(\n",
        "                contents=contents\n",
        "            )\n",
        "            print(\"\\nGeminiからの最終的な応答:\")\n",
        "            display(Markdown(final_response.text))\n",
        "\n",
        "    else:\n",
        "        print(f\"不明なツール呼び出し: {function_name}\")\n",
        "else:\n",
        "    # If the response is text\n",
        "    print(\"\\nGeminiからのテキスト応答:\")\n",
        "    display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "tiV9PJiyNq-B",
        "outputId": "5515a2f7-8687-48da-e6c4-d69f6ab2bc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ユーザーのプロンプト: ライトをオンにして、10秒待ってからオフにして。\n",
            "Geminiが応答を生成中...\n",
            "\n",
            "Geminiからのテキスト応答:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "10秒待つ、という動作はサポートしていません。ライトをオン・オフすることのみ実行できますが、いかがいたしますか？"
          },
          "metadata": {}
        }
      ]
    }
  ]
}